{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:59:39.021336Z",
     "iopub.status.busy": "2023-12-21T15:59:39.020915Z",
     "iopub.status.idle": "2023-12-21T15:59:50.617401Z",
     "shell.execute_reply": "2023-12-21T15:59:50.615942Z",
     "shell.execute_reply.started": "2023-12-21T15:59:39.021299Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install plot_keras_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-21T15:59:50.621753Z",
     "iopub.status.busy": "2023-12-21T15:59:50.620371Z",
     "iopub.status.idle": "2023-12-21T15:59:50.633154Z",
     "shell.execute_reply": "2023-12-21T15:59:50.632135Z",
     "shell.execute_reply.started": "2023-12-21T15:59:50.621701Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize, LabelEncoder\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from plot_keras_history import show_history, plot_history\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# For normalization and preparation\n",
    "import cv2\n",
    "from skimage.exposure import match_histograms\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#For tiling\n",
    "from PIL import Image\n",
    "\n",
    "# os.environ[\"TF_KERAS\"]='1'\n",
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:59:50.634841Z",
     "iopub.status.busy": "2023-12-21T15:59:50.634516Z",
     "iopub.status.idle": "2023-12-21T15:59:50.905035Z",
     "shell.execute_reply": "2023-12-21T15:59:50.904022Z",
     "shell.execute_reply.started": "2023-12-21T15:59:50.634811Z"
    }
   },
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "data = pd.read_csv('/kaggle/input/UBC-OCEAN/train.csv')\n",
    "data['image_path'] = [''.join(['/kaggle/input/UBC-OCEAN/train_thumbnails/', str(x), '_thumbnail.png']) if ''.join([str(x), '_thumbnail.png']) in os.listdir('/kaggle/input/UBC-OCEAN/train_thumbnails') else ''.join(['/kaggle/input/UBC-OCEAN/train_images/', str(x), '.png']) for x in data['image_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:59:50.908418Z",
     "iopub.status.busy": "2023-12-21T15:59:50.907937Z",
     "iopub.status.idle": "2023-12-21T15:59:50.915812Z",
     "shell.execute_reply": "2023-12-21T15:59:50.914691Z",
     "shell.execute_reply.started": "2023-12-21T15:59:50.908376Z"
    }
   },
   "outputs": [],
   "source": [
    "# Nombre de classes\n",
    "nb_lab = len(data['label'].unique())\n",
    "\n",
    "# Liste des classes\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(data['label'])\n",
    "list_lab = le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:59:50.917949Z",
     "iopub.status.busy": "2023-12-21T15:59:50.917300Z",
     "iopub.status.idle": "2023-12-21T15:59:50.927119Z",
     "shell.execute_reply": "2023-12-21T15:59:50.926103Z",
     "shell.execute_reply.started": "2023-12-21T15:59:50.917909Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:59:50.929021Z",
     "iopub.status.busy": "2023-12-21T15:59:50.928491Z",
     "iopub.status.idle": "2023-12-21T15:59:50.938977Z",
     "shell.execute_reply": "2023-12-21T15:59:50.938071Z",
     "shell.execute_reply.started": "2023-12-21T15:59:50.928980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fonction d'augmentation des données\n",
    "def data_flow_fct(data, datagen, data_type=None, batch_size=None) :\n",
    "\n",
    "    data_flow = datagen.flow_from_dataframe(data,\n",
    "                                            #directory=dir_, # Pas besoin\n",
    "                                            x_col='image_path',  # Utilisez 'image_path' comme colonne des chemins d'images\n",
    "                                            y_col='label',#_name',\n",
    "                                            weight_col=None,\n",
    "                                            target_size=(256, 256),\n",
    "                                            classes=None,\n",
    "                                            class_mode='categorical',\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            seed=42,\n",
    "                                            subset=data_type)\n",
    "    return data_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:59:50.940770Z",
     "iopub.status.busy": "2023-12-21T15:59:50.940402Z",
     "iopub.status.idle": "2023-12-21T15:59:50.953755Z",
     "shell.execute_reply": "2023-12-21T15:59:50.952626Z",
     "shell.execute_reply.started": "2023-12-21T15:59:50.940742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Méthode d'augmentation des données\n",
    "datagen_train = ImageDataGenerator(\n",
    "#    featurewise_center=True,\n",
    "#    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.25,# détermine le ration training/validation\n",
    "    preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Train/Val split on augmentated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:59:50.955400Z",
     "iopub.status.busy": "2023-12-21T15:59:50.955001Z",
     "iopub.status.idle": "2023-12-21T15:59:51.181581Z",
     "shell.execute_reply": "2023-12-21T15:59:51.180783Z",
     "shell.execute_reply.started": "2023-12-21T15:59:50.955369Z"
    }
   },
   "outputs": [],
   "source": [
    "# Augmentation des données et split en train et val\n",
    "train_flow = data_flow_fct(data, datagen_train, data_type='training',batch_size=batch_size)#divisor_train)\n",
    "val_flow = data_flow_fct(data, datagen_train, data_type='validation',batch_size=batch_size)#divisor_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:59:51.183500Z",
     "iopub.status.busy": "2023-12-21T15:59:51.182946Z",
     "iopub.status.idle": "2023-12-21T15:59:51.196418Z",
     "shell.execute_reply": "2023-12-21T15:59:51.195556Z",
     "shell.execute_reply.started": "2023-12-21T15:59:51.183467Z"
    }
   },
   "outputs": [],
   "source": [
    "    def pad_to_size(tile, target_size):\n",
    "        # Calcule la quantité de padding nécessaire\n",
    "        pad_height = max(0, target_size[0] - tile.shape[0])\n",
    "        pad_width = max(0, target_size[1] - tile.shape[1])\n",
    "    \n",
    "        # Ajoute des colonnes de zéros à gauche et à droite\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "    \n",
    "        # Ajoute des lignes de zéros en haut et en bas\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "    \n",
    "        # Applique le padding\n",
    "        padded_tile = np.pad(tile, ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)), mode='constant', constant_values=0)\n",
    "    \n",
    "        return padded_tile\n",
    "\n",
    "    def tiling(image_path, tile_size=224, pix_threshold=0.6):\n",
    "        # Découper l'image en petits carreaux\n",
    "        # 1. Charger l'image\n",
    "        #image_path = r\"C:\\Users\\John\\Desktop\\KA-CL-P2-Ovarian_Cancer_Classification\\img_paris.png\"\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 2. Convertir en numpy array\n",
    "        image_array = np.array(image)\n",
    "        \n",
    "        # 3. Tiling de l'image en carreaux de tile_size par tile_size\n",
    "        #tile_size = 224\n",
    "        tiles = [pad_to_size(image_array[i:i+tile_size, j:j+tile_size], (tile_size, tile_size, 3)) for i in range(0, image_array.shape[0], tile_size) for j in range(0, image_array.shape[1], tile_size)]\n",
    "        \n",
    "        # 4. Élimination des carreaux de taille inférieure à un certain threshold\n",
    "        threshold = pix_threshold * tile_size**2 * 3 # Vous pouvez ajuster ce seuil en fonction de vos besoins\n",
    "        filtered_tiles = [tile for tile in tiles if np.sum(tile) > threshold]\n",
    "        \n",
    "        # 5. Reconstruction d'un numpy array carré avec les tiles restant\n",
    "        num_tiles_side = int(np.sqrt(len(filtered_tiles)))\n",
    "    \n",
    "        if (len(filtered_tiles) - num_tiles_side**2) != 0:\n",
    "            num_blank_tiles = (num_tiles_side+1)**2 - num_tiles_side**2\n",
    "            num_tiles_side = num_tiles_side + 1\n",
    "        else:\n",
    "            num_blank_tiles = 0\n",
    "            \n",
    "        # Création de tiles blancs\n",
    "        blank_tile = np.zeros((tile_size, tile_size, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Remplissage des tiles manquants avec des tiles blanches\n",
    "        filled_tiles = filtered_tiles + [blank_tile] * num_blank_tiles\n",
    "        \n",
    "        # Reconstruction du numpy array carré\n",
    "        reconstructed_array = np.vstack([np.hstack(filled_tiles[i*num_tiles_side:(i+1)*num_tiles_side]) for i in range(num_tiles_side)])\n",
    "        \n",
    "        # 6. Enregistrement au format png\n",
    "        #reconstructed_image = Image.fromarray(reconstructed_array)\n",
    "        reconstructed_image = cv2.convertScaleAbs(reconstructed_array, cv2.COLOR_LAB2BGR)\n",
    "        reconstructed_image = cv2.resize(reconstructed_image, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        #base_name = os.path.basename(image_path)\n",
    "        # Create the folder if it doesn't exist\n",
    "        #os.makedirs(r\"reconstructed/\", exist_ok=True)\n",
    "        #folder = r\"reconstructed/\"\n",
    "        #full_name = ''.join([folder, base_name])\n",
    "        #reconstructed_image.save(full_name)\n",
    "        return reconstructed_image\n",
    "        #return reconstructed_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:59:51.200966Z",
     "iopub.status.busy": "2023-12-21T15:59:51.200160Z",
     "iopub.status.idle": "2023-12-21T15:59:53.881544Z",
     "shell.execute_reply": "2023-12-21T15:59:53.880336Z",
     "shell.execute_reply.started": "2023-12-21T15:59:51.200921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Afficher une image avant et après tiling\n",
    "une_image = '/kaggle/input/UBC-OCEAN/train_thumbnails/4_thumbnail.png'\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax[0].imshow(plt.imread(une_image))\n",
    "\n",
    "ax[1].imshow(tiling(une_image))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Image preparation for VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:59:53.883152Z",
     "iopub.status.busy": "2023-12-21T15:59:53.882834Z",
     "iopub.status.idle": "2023-12-21T15:59:53.891932Z",
     "shell.execute_reply": "2023-12-21T15:59:53.890803Z",
     "shell.execute_reply.started": "2023-12-21T15:59:53.883123Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fonction de préparation des images tilées au format np.array\n",
    "#3mn36\n",
    "def image_prep_fct_tiling(data):\n",
    "    prepared_images = []\n",
    "    prepared_images_np = np.empty((0, 0))\n",
    "    \n",
    "    for path in data['image_path']:\n",
    "        img = None\n",
    "        try:\n",
    "            # Load tiled image\n",
    "            img = tiling(path)\n",
    "            #print(len(img.shape))\n",
    "        except:\n",
    "            # Handle the exception if needed\n",
    "            print(\"failed to tile image {path}\")\n",
    "            pass\n",
    "\n",
    "        # Check the number of channels in the image\n",
    "        if len(img.shape) == 2:\n",
    "            # If the image has only one channel, replicate it to create a three-channel image\n",
    "            img = np.stack((img, img, img), axis=-1)\n",
    "\n",
    "        # Assuming target_size for img_to_array is (224, 224)\n",
    "        img = img_to_array(img)\n",
    "        img = img.reshape((img.shape[0], img.shape[1], img.shape[2]))\n",
    "        #print(img.shape[0], img.shape[1], img.shape[2])\n",
    "        img = preprocess_input(img)\n",
    "        prepared_images.append(img)\n",
    "        prepared_images_np = np.array(prepared_images)\n",
    "    \n",
    "    return prepared_images_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T15:59:53.893955Z",
     "iopub.status.busy": "2023-12-21T15:59:53.893567Z",
     "iopub.status.idle": "2023-12-21T16:04:03.666006Z",
     "shell.execute_reply": "2023-12-21T16:04:03.664857Z",
     "shell.execute_reply.started": "2023-12-21T15:59:53.893919Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "images_np_tiled = image_prep_fct_tiling(data)\n",
    "print(images_np_tiled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T16:04:59.797912Z",
     "iopub.status.busy": "2023-12-21T16:04:59.796171Z",
     "iopub.status.idle": "2023-12-21T16:04:59.811732Z",
     "shell.execute_reply": "2023-12-21T16:04:59.810394Z",
     "shell.execute_reply.started": "2023-12-21T16:04:59.797845Z"
    }
   },
   "outputs": [],
   "source": [
    "# Définition des X et y pour le training et validation et des X_test et y_test pour le test\n",
    "X = images_np_tiled\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(data['label'])\n",
    "y = to_categorical(labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T16:04:59.814891Z",
     "iopub.status.busy": "2023-12-21T16:04:59.814408Z",
     "iopub.status.idle": "2023-12-21T16:04:59.825128Z",
     "shell.execute_reply": "2023-12-21T16:04:59.824209Z",
     "shell.execute_reply.started": "2023-12-21T16:04:59.814852Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fonction de création du modèle\n",
    "def create_model_fct() :\n",
    "    #weights_path = \"/kaggle/input/vgg16-weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\" # ATTENTION : activer hors connexion\n",
    "    weights_path = 'imagenet'\n",
    "    # Charger le modèle VGG16 pré-entraîné\n",
    "    #base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    model0 = VGG16(include_top=False, weights=weights_path, input_shape=(224, 224, 3)) # ATTENTION : activer hors connexion\n",
    "    \n",
    "    # Layer non entraînables = on garde les poids du modèle pré-entraîné\n",
    "    for layer in model0.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Récupérer la sortie de ce réseau\n",
    "    x = model0.output\n",
    "    # Compléter le modèle\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(nb_lab, activation='softmax')(x)\n",
    "\n",
    "    # Définir le nouveau modèle\n",
    "    model = Model(inputs=model0.input, outputs=predictions)\n",
    "    # compilation du modèle \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=[\"accuracy\"])\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T16:04:59.827530Z",
     "iopub.status.busy": "2023-12-21T16:04:59.826750Z",
     "iopub.status.idle": "2023-12-21T16:05:01.744957Z",
     "shell.execute_reply": "2023-12-21T16:05:01.741651Z",
     "shell.execute_reply.started": "2023-12-21T16:04:59.827491Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Création du modèle\n",
    "# 408ms\n",
    "with tf.device('/gpu:1'): \n",
    "    model = create_model_fct()\n",
    "\n",
    "# Création du callback\n",
    "model_save_path = \"./model_best_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(model_save_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=5)\n",
    "callbacks_list = [checkpoint, es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T16:06:02.180150Z",
     "iopub.status.busy": "2023-12-21T16:06:02.179670Z",
     "iopub.status.idle": "2023-12-21T17:10:19.127513Z",
     "shell.execute_reply": "2023-12-21T17:10:19.126355Z",
     "shell.execute_reply.started": "2023-12-21T16:06:02.180113Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 4min35 for epochs = 1 and batch_size = 32\n",
    "# Entraîner sur les données d'entraînement\n",
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit(train_flow, epochs=epochs, \n",
    "                        steps_per_epoch=len(train_flow),\n",
    "                        callbacks=callbacks_list, \n",
    "                        validation_data=val_flow,\n",
    "                        validation_steps=len(val_flow),\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T17:11:59.873505Z",
     "iopub.status.busy": "2023-12-21T17:11:59.872344Z",
     "iopub.status.idle": "2023-12-21T17:12:01.249521Z",
     "shell.execute_reply": "2023-12-21T17:12:01.248267Z",
     "shell.execute_reply.started": "2023-12-21T17:11:59.873461Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Visualisation de l'évolution des performances/epoch\n",
    "show_history(history)\n",
    "plot_history(history, path=\"history.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T17:10:19.137175Z",
     "iopub.status.busy": "2023-12-21T17:10:19.136745Z",
     "iopub.status.idle": "2023-12-21T17:11:23.589924Z",
     "shell.execute_reply": "2023-12-21T17:11:23.588643Z",
     "shell.execute_reply.started": "2023-12-21T17:10:19.137138Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# y_pred\n",
    "#1min 28 for batch_size = 32\n",
    "y_pred = model.predict(val_flow, steps=len(val_flow), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T17:14:12.078784Z",
     "iopub.status.busy": "2023-12-21T17:14:12.078368Z",
     "iopub.status.idle": "2023-12-21T17:14:40.971702Z",
     "shell.execute_reply": "2023-12-21T17:14:40.970447Z",
     "shell.execute_reply.started": "2023-12-21T17:14:12.078751Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# y_val\n",
    "# 29s for batch_size = 32\n",
    "# Nombre total d'échantillons dans le jeu de validation\n",
    "nombre_total_val = len(val_flow) * batch_size\n",
    "\n",
    "# Initialisation d'un tableau pour stocker les étiquettes réelles\n",
    "y_val = np.zeros((nombre_total_val, nb_lab))  \n",
    "\n",
    "# Itérer sur le générateur pour extraire les étiquettes réelles\n",
    "for i in range(len(val_flow)):\n",
    "    _, batch_y_val = val_flow[i]  # Supposons que le générateur génère des paires (X_val, y_val)\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + len(batch_y_val)\n",
    "    y_val[start_index:end_index] = batch_y_val\n",
    "\n",
    "# Maintenant, y_val contient les étiquettes réelles correspondantes aux prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T17:16:01.693115Z",
     "iopub.status.busy": "2023-12-21T17:16:01.692660Z",
     "iopub.status.idle": "2023-12-21T17:16:01.712051Z",
     "shell.execute_reply": "2023-12-21T17:16:01.710783Z",
     "shell.execute_reply.started": "2023-12-21T17:16:01.693076Z"
    }
   },
   "outputs": [],
   "source": [
    "# Générer la matrice de confusion\n",
    "cm = confusion_matrix(y_val.argmax(axis=1)[0:len(y_pred)], y_pred.argmax(axis=1))\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "print(\"Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_val.argmax(axis=1)[0:len(y_pred)], y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T17:17:00.921938Z",
     "iopub.status.busy": "2023-12-21T17:17:00.921472Z",
     "iopub.status.idle": "2023-12-21T17:17:01.208337Z",
     "shell.execute_reply": "2023-12-21T17:17:01.207129Z",
     "shell.execute_reply.started": "2023-12-21T17:17:00.921902Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cm, index=list_lab, columns=list_lab)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "\n",
    "# Ajouter des étiquettes aux axes\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6924515,
     "sourceId": 45867,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
