{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:06.894155Z",
     "iopub.status.busy": "2024-01-03T17:40:06.893668Z",
     "iopub.status.idle": "2024-01-03T17:40:21.325686Z",
     "shell.execute_reply": "2024-01-03T17:40:21.324182Z",
     "shell.execute_reply.started": "2024-01-03T17:40:06.894117Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install plot_keras_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:21.329875Z",
     "iopub.status.busy": "2024-01-03T17:40:21.329370Z",
     "iopub.status.idle": "2024-01-03T17:40:21.341951Z",
     "shell.execute_reply": "2024-01-03T17:40:21.340327Z",
     "shell.execute_reply.started": "2024-01-03T17:40:21.329826Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize, LabelEncoder\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from plot_keras_history import show_history, plot_history\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# For normalization\n",
    "import cv2\n",
    "from skimage.exposure import match_histograms\n",
    "\n",
    "# os.environ[\"TF_KERAS\"]='1'\n",
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:21.343824Z",
     "iopub.status.busy": "2024-01-03T17:40:21.343426Z",
     "iopub.status.idle": "2024-01-03T17:40:21.754259Z",
     "shell.execute_reply": "2024-01-03T17:40:21.753014Z",
     "shell.execute_reply.started": "2024-01-03T17:40:21.343792Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "df = pd.read_csv('/kaggle/input/UBC-OCEAN/train.csv')\n",
    "df['image_path'] = [''.join(['/kaggle/input/UBC-OCEAN/train_thumbnails/', str(x), '_thumbnail.png']) if ''.join([str(x), '_thumbnail.png']) in os.listdir('/kaggle/input/UBC-OCEAN/train_thumbnails') else ''.join(['/kaggle/input/UBC-OCEAN/train_images/', str(x), '.png']) for x in df['image_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:21.758113Z",
     "iopub.status.busy": "2024-01-03T17:40:21.757671Z",
     "iopub.status.idle": "2024-01-03T17:40:21.765873Z",
     "shell.execute_reply": "2024-01-03T17:40:21.764329Z",
     "shell.execute_reply.started": "2024-01-03T17:40:21.758072Z"
    }
   },
   "outputs": [],
   "source": [
    "# For testing\n",
    "X_df = df.drop(columns='label')\n",
    "y_df = df['label']\n",
    "\n",
    "X,X_test,y,y_test = train_test_split(X_df, y_df, train_size=0.1, stratify = df['label'])\n",
    "\n",
    "data = pd.DataFrame(X, columns = list(df.columns).remove('label'))\n",
    "data['label'] = y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:21.883091Z",
     "iopub.status.busy": "2024-01-03T17:40:21.882118Z",
     "iopub.status.idle": "2024-01-03T17:40:21.895202Z",
     "shell.execute_reply": "2024-01-03T17:40:21.893965Z",
     "shell.execute_reply.started": "2024-01-03T17:40:21.883047Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:21.897525Z",
     "iopub.status.busy": "2024-01-03T17:40:21.897088Z",
     "iopub.status.idle": "2024-01-03T17:40:22.127794Z",
     "shell.execute_reply": "2024-01-03T17:40:22.126293Z",
     "shell.execute_reply.started": "2024-01-03T17:40:21.897466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Comptez combien de fois chaque catégorie apparaît dans la colonne 'label'\n",
    "label_counts = data['label'].value_counts()\n",
    "\n",
    "# Créez un pie chart en utilisant les données de 'label_counts'\n",
    "plt.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:22.131047Z",
     "iopub.status.busy": "2024-01-03T17:40:22.130161Z",
     "iopub.status.idle": "2024-01-03T17:40:22.144815Z",
     "shell.execute_reply": "2024-01-03T17:40:22.143341Z",
     "shell.execute_reply.started": "2024-01-03T17:40:22.130990Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['method','val_accuracy', 'processing_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Model1 : Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:22.157600Z",
     "iopub.status.busy": "2024-01-03T17:40:22.152744Z",
     "iopub.status.idle": "2024-01-03T17:40:22.165994Z",
     "shell.execute_reply": "2024-01-03T17:40:22.164551Z",
     "shell.execute_reply.started": "2024-01-03T17:40:22.157524Z"
    }
   },
   "outputs": [],
   "source": [
    "chrono = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:22.172337Z",
     "iopub.status.busy": "2024-01-03T17:40:22.171252Z",
     "iopub.status.idle": "2024-01-03T17:40:22.181192Z",
     "shell.execute_reply": "2024-01-03T17:40:22.180270Z",
     "shell.execute_reply.started": "2024-01-03T17:40:22.172291Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of classes\n",
    "nb_lab = len(data['label'].unique())\n",
    "\n",
    "# Class list\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(data['label'])\n",
    "list_lab = le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:22.183403Z",
     "iopub.status.busy": "2024-01-03T17:40:22.182487Z",
     "iopub.status.idle": "2024-01-03T17:40:22.190660Z",
     "shell.execute_reply": "2024-01-03T17:40:22.189792Z",
     "shell.execute_reply.started": "2024-01-03T17:40:22.183371Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:22.192930Z",
     "iopub.status.busy": "2024-01-03T17:40:22.191817Z",
     "iopub.status.idle": "2024-01-03T17:40:22.201907Z",
     "shell.execute_reply": "2024-01-03T17:40:22.200846Z",
     "shell.execute_reply.started": "2024-01-03T17:40:22.192895Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fonction d'augmentation des données\n",
    "def data_flow_fct(data, datagen, data_type=None, batch_size=None) :\n",
    "\n",
    "    data_flow = datagen.flow_from_dataframe(data,\n",
    "                                            #directory=dir_, # Pas besoin\n",
    "                                            x_col='image_path',  # Utilisez 'image_path' comme colonne des chemins d'images\n",
    "                                            y_col='label',#_name',\n",
    "                                            weight_col=None,\n",
    "                                            target_size=(256, 256),\n",
    "                                            classes=None,\n",
    "                                            class_mode='categorical',\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            seed=42,\n",
    "                                            subset=data_type)\n",
    "    return data_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:22.203796Z",
     "iopub.status.busy": "2024-01-03T17:40:22.203467Z",
     "iopub.status.idle": "2024-01-03T17:40:22.213246Z",
     "shell.execute_reply": "2024-01-03T17:40:22.212038Z",
     "shell.execute_reply.started": "2024-01-03T17:40:22.203766Z"
    }
   },
   "outputs": [],
   "source": [
    "# Méthode d'augmentation des données\n",
    "datagen_train = ImageDataGenerator(\n",
    "#    featurewise_center=True,\n",
    "#    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.25,# détermine le ration training/validation\n",
    "    preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:22.216932Z",
     "iopub.status.busy": "2024-01-03T17:40:22.216495Z",
     "iopub.status.idle": "2024-01-03T17:40:22.228300Z",
     "shell.execute_reply": "2024-01-03T17:40:22.227285Z",
     "shell.execute_reply.started": "2024-01-03T17:40:22.216890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fonction de création du modèle\n",
    "def create_model_fct(nb_lab) :\n",
    "    #weights_path = \"/kaggle/input/vgg16-weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\" # ATTENTION : activer hors connexion\n",
    "    weights_path = 'imagenet'\n",
    "    # Charger le modèle VGG16 pré-entraîné\n",
    "    #base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    model0 = VGG16(include_top=False, weights=weights_path, input_shape=(224, 224, 3)) # ATTENTION : activer hors connexion\n",
    "    \n",
    "    # Layer non entraînables = on garde les poids du modèle pré-entraîné\n",
    "    for layer in model0.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Récupérer la sortie de ce réseau\n",
    "    x = model0.output\n",
    "    # Compléter le modèle\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(nb_lab, activation='softmax')(x)\n",
    "\n",
    "    # Définir le nouveau modèle\n",
    "    model = Model(inputs=model0.input, outputs=predictions)\n",
    "    # compilation du modèle \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=[\"accuracy\"])\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:22.230648Z",
     "iopub.status.busy": "2024-01-03T17:40:22.229680Z",
     "iopub.status.idle": "2024-01-03T17:40:22.272936Z",
     "shell.execute_reply": "2024-01-03T17:40:22.271752Z",
     "shell.execute_reply.started": "2024-01-03T17:40:22.230615Z"
    }
   },
   "outputs": [],
   "source": [
    "# Augmentation des données et split en train et val\n",
    "train_flow = data_flow_fct(data, datagen_train, data_type='training',batch_size=batch_size)#divisor_train)\n",
    "val_flow = data_flow_fct(data, datagen_train, data_type='validation',batch_size=batch_size)#divisor_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:22.275646Z",
     "iopub.status.busy": "2024-01-03T17:40:22.274456Z",
     "iopub.status.idle": "2024-01-03T17:40:25.407801Z",
     "shell.execute_reply": "2024-01-03T17:40:25.406547Z",
     "shell.execute_reply.started": "2024-01-03T17:40:22.275608Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Model creation\n",
    "# 408ms\n",
    "\n",
    "with tf.device('/gpu:1'): \n",
    "    model = create_model_fct(nb_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:40:25.410524Z",
     "iopub.status.busy": "2024-01-03T17:40:25.410060Z",
     "iopub.status.idle": "2024-01-03T17:41:14.197565Z",
     "shell.execute_reply": "2024-01-03T17:41:14.196217Z",
     "shell.execute_reply.started": "2024-01-03T17:40:25.410482Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 4min35 for epochs = 1 and batch_size = 32\n",
    "# Model training\n",
    "with tf.device('/gpu:1'):\n",
    "    \n",
    "    # Call back creation\n",
    "    model_save_path = \"model_best_weights_1.h5\"\n",
    "    checkpoint = ModelCheckpoint(model_save_path, monitor='val_accuracy', verbose=1, mode='max', save_best_only=True)\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "    \n",
    "    # Training\n",
    "    history = model.fit(train_flow, epochs=epochs, \n",
    "                        steps_per_epoch=len(train_flow),\n",
    "                        callbacks=callbacks_list, \n",
    "                        validation_data=val_flow,\n",
    "                        validation_steps=len(val_flow),\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:41:15.273903Z",
     "iopub.status.busy": "2024-01-03T17:41:15.273408Z",
     "iopub.status.idle": "2024-01-03T17:41:26.303794Z",
     "shell.execute_reply": "2024-01-03T17:41:26.302680Z",
     "shell.execute_reply.started": "2024-01-03T17:41:15.273869Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Performances\n",
    "print('1/6-val accuracy/epochs')\n",
    "show_history(history)\n",
    "plot_history(history, path=\"history.png\")\n",
    "plt.close()\n",
    "\n",
    "print('2/6-predicting y_pred')\n",
    "#1min 28 for batch_size = 32\n",
    "y_pred = model.predict(val_flow, steps=len(val_flow), batch_size=batch_size)\n",
    "\n",
    "print('3/6-getting y_val')\n",
    "nombre_total_val = len(val_flow) * batch_size\n",
    "\n",
    "# Initialisation d'un tableau pour stocker les étiquettes réelles\n",
    "y_val = np.zeros((nombre_total_val, nb_lab))  \n",
    "\n",
    "# Itérer sur le générateur pour extraire les étiquettes réelles\n",
    "for i in range(len(val_flow)):\n",
    "    _, batch_y_val = val_flow[i]  # Supposons que le générateur génère des paires (X_val, y_val)\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + len(batch_y_val)\n",
    "    y_val[start_index:end_index] = batch_y_val\n",
    "\n",
    "print('4/6-building the basic confusion matrix')\n",
    "# Obtenez les indices des classes prédites et réelles pour les échantillons disponibles\n",
    "y_val_indices = y_val.argmax(axis=1)[0:len(y_pred)]\n",
    "y_pred_indices = y_pred.argmax(axis=1)\n",
    "\n",
    "# Générer la matrice de confusion\n",
    "cm = confusion_matrix(y_val_indices, y_pred_indices)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "print(cm)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(\"\\n5/6-building the classification report\")\n",
    "print(classification_report(y_val.argmax(axis=1)[0:len(y_pred)], y_pred.argmax(axis=1)))\n",
    "\n",
    "print('6/6-building the sns confusion matrix')\n",
    "# Finding the matching categorical labels for the numerical labels\n",
    "list_num_labels = sorted([x for x in set(y_val_indices)|set(y_pred_indices)])\n",
    "list_cat_labels = le.inverse_transform(list_num_labels)\n",
    "\n",
    "# Proceding with sns\n",
    "df_cm = pd.DataFrame(cm, index=list_cat_labels, columns=list_cat_labels)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "\n",
    "# Ajouter des étiquettes aux axes\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:41:26.305718Z",
     "iopub.status.busy": "2024-01-03T17:41:26.305366Z",
     "iopub.status.idle": "2024-01-03T17:41:26.312896Z",
     "shell.execute_reply": "2024-01-03T17:41:26.311713Z",
     "shell.execute_reply.started": "2024-01-03T17:41:26.305687Z"
    }
   },
   "outputs": [],
   "source": [
    "# recording method,val_accuracy, processing_time\n",
    "chrono = time() - chrono\n",
    "results.loc[len(results)] = ['Model1 : Data augmentation',history.history['val_accuracy'][-1],chrono]\n",
    "chrono = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Model2 : Data augmentation + Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:41:26.324451Z",
     "iopub.status.busy": "2024-01-03T17:41:26.323769Z",
     "iopub.status.idle": "2024-01-03T17:41:26.332850Z",
     "shell.execute_reply": "2024-01-03T17:41:26.331661Z",
     "shell.execute_reply.started": "2024-01-03T17:41:26.324410Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalization function (input : image - output : np.array)\n",
    "def normalization_processing_np_np(np_image):\n",
    "    # Appliquer une normalisation de l'image sur le modèle d'une image de référence ref_path\n",
    "    ref_path = r\"/kaggle/input/UBC-OCEAN/train_thumbnails/4_thumbnail.png\"\n",
    "\n",
    "    # Charger l'image en couleur\n",
    "    ref_img = cv2.imread(ref_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "    #image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Resize des images pour avoir la même taille\n",
    "    ref_img = cv2.resize(ref_img, (2000, 2000), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    image = cv2.resize(np_image, (2000, 2000), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Appliquer la normalisation\n",
    "    aft_img = match_histograms(image, ref_img)\n",
    "\n",
    "    # Convert the image to uint8 and BGR\n",
    "    aft_img = cv2.convertScaleAbs(aft_img, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return aft_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:41:26.334619Z",
     "iopub.status.busy": "2024-01-03T17:41:26.334269Z",
     "iopub.status.idle": "2024-01-03T17:41:31.027863Z",
     "shell.execute_reply": "2024-01-03T17:41:31.026827Z",
     "shell.execute_reply.started": "2024-01-03T17:41:26.334588Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example of an image Before and After normalization\n",
    "image_path = '/kaggle/input/UBC-OCEAN/train_thumbnails/10143_thumbnail.png'\n",
    "np_image = cv2.imread(image_path)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax[0].imshow(plt.imread(image_path))\n",
    "\n",
    "ax[1].imshow(normalization_processing_np_np(np_image))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:41:31.030163Z",
     "iopub.status.busy": "2024-01-03T17:41:31.029275Z",
     "iopub.status.idle": "2024-01-03T17:41:31.035011Z",
     "shell.execute_reply": "2024-01-03T17:41:31.033991Z",
     "shell.execute_reply.started": "2024-01-03T17:41:31.030124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data augmentation method\n",
    "datagen_train = ImageDataGenerator(\n",
    "#    featurewise_center=True,\n",
    "#    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.25,# détermine le ratio training/validation\n",
    "    preprocessing_function=normalization_processing_np_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:41:31.036744Z",
     "iopub.status.busy": "2024-01-03T17:41:31.036399Z",
     "iopub.status.idle": "2024-01-03T17:41:36.837498Z",
     "shell.execute_reply": "2024-01-03T17:41:36.836402Z",
     "shell.execute_reply.started": "2024-01-03T17:41:31.036713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example of data augmentation + normalization\n",
    "image_path = '/kaggle/input/UBC-OCEAN/train_thumbnails/10143_thumbnail.png'\n",
    "img = cv2.imread(image_path) #/ 255.0  # Normalisez les valeurs de pixel à l'intervalle [0, 1]\n",
    "img = cv2.resize(img, (2000, 2000), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Add a dimension to get shape(1, height, width, channels)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Apply preprocessing to image\n",
    "for img_batch in datagen_train.flow(img, batch_size=1):\n",
    "    img_augmented = img_batch[0]/255\n",
    "    break  # Break after first batch because we only have one\n",
    "\n",
    "# To make sure we have the good format (height, width, channels)\n",
    "#img_augmented = img_augmented.squeeze()\n",
    "\n",
    "# Display image Before and After\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img.squeeze())\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_augmented)\n",
    "plt.title('Augmented Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:41:36.839127Z",
     "iopub.status.busy": "2024-01-03T17:41:36.838802Z",
     "iopub.status.idle": "2024-01-03T17:42:01.876152Z",
     "shell.execute_reply": "2024-01-03T17:42:01.874793Z",
     "shell.execute_reply.started": "2024-01-03T17:41:36.839099Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 4min35 for epochs = 1 and batch_size = 32\n",
    "# Model training\n",
    "with tf.device('/gpu:1'):\n",
    "    \n",
    "    # Call back creation\n",
    "    model_save_path = \"model_best_weights_2.h5\"\n",
    "    checkpoint = ModelCheckpoint(model_save_path, monitor='val_accuracy', verbose=1, mode='max', save_best_only=True)\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "    \n",
    "    # Training\n",
    "    history = model.fit(train_flow, epochs=epochs, \n",
    "                        steps_per_epoch=len(train_flow),\n",
    "                        callbacks=callbacks_list, \n",
    "                        validation_data=val_flow,\n",
    "                        validation_steps=len(val_flow),\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:01.878145Z",
     "iopub.status.busy": "2024-01-03T17:42:01.877681Z",
     "iopub.status.idle": "2024-01-03T17:42:12.503977Z",
     "shell.execute_reply": "2024-01-03T17:42:12.502795Z",
     "shell.execute_reply.started": "2024-01-03T17:42:01.878109Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Performances\n",
    "print('1/6-val accuracy/epochs')\n",
    "show_history(history)\n",
    "plot_history(history, path=\"history.png\")\n",
    "plt.close()\n",
    "\n",
    "print('2/6-predicting y_pred')\n",
    "#1min 28 for batch_size = 32\n",
    "y_pred = model.predict(val_flow, steps=len(val_flow), batch_size=batch_size)\n",
    "\n",
    "print('3/6-getting y_val')\n",
    "nombre_total_val = len(val_flow) * batch_size\n",
    "\n",
    "# Initialisation d'un tableau pour stocker les étiquettes réelles\n",
    "y_val = np.zeros((nombre_total_val, nb_lab))  \n",
    "\n",
    "# Itérer sur le générateur pour extraire les étiquettes réelles\n",
    "for i in range(len(val_flow)):\n",
    "    _, batch_y_val = val_flow[i]  # Supposons que le générateur génère des paires (X_val, y_val)\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + len(batch_y_val)\n",
    "    y_val[start_index:end_index] = batch_y_val\n",
    "\n",
    "print('4/6-building the basic confusion matrix')\n",
    "# Obtenez les indices des classes prédites et réelles pour les échantillons disponibles\n",
    "y_val_indices = y_val.argmax(axis=1)[0:len(y_pred)]\n",
    "y_pred_indices = y_pred.argmax(axis=1)\n",
    "\n",
    "# Générer la matrice de confusion\n",
    "cm = confusion_matrix(y_val_indices, y_pred_indices)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "print(cm)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(\"\\n5/6-building the classification report\")\n",
    "print(classification_report(y_val.argmax(axis=1)[0:len(y_pred)], y_pred.argmax(axis=1)))\n",
    "\n",
    "print('6/6-building the sns confusion matrix')\n",
    "# Finding the matching categorical labels for the numerical labels\n",
    "list_num_labels = sorted([x for x in set(y_val_indices)|set(y_pred_indices)])\n",
    "list_cat_labels = le.inverse_transform(list_num_labels)\n",
    "\n",
    "# Proceding with sns\n",
    "df_cm = pd.DataFrame(cm, index=list_cat_labels, columns=list_cat_labels)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "\n",
    "# Ajouter des étiquettes aux axes\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:12.506335Z",
     "iopub.status.busy": "2024-01-03T17:42:12.505564Z",
     "iopub.status.idle": "2024-01-03T17:42:12.516685Z",
     "shell.execute_reply": "2024-01-03T17:42:12.515012Z",
     "shell.execute_reply.started": "2024-01-03T17:42:12.506288Z"
    }
   },
   "outputs": [],
   "source": [
    "# recording method,val_accuracy, processing_time\n",
    "chrono = time() - chrono\n",
    "results.loc[len(results)] = ['Model2 : Data augmentation + Normalization',history.history['val_accuracy'][-1],chrono]\n",
    "chrono = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Model3 : Data augmentation + Tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:12.518986Z",
     "iopub.status.busy": "2024-01-03T17:42:12.518470Z",
     "iopub.status.idle": "2024-01-03T17:42:12.535270Z",
     "shell.execute_reply": "2024-01-03T17:42:12.533879Z",
     "shell.execute_reply.started": "2024-01-03T17:42:12.518952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tiling function\n",
    "def tiling_np_np(image_array, tile_size=224, pix_threshold=100):\n",
    "    # pix_threshold must be between 0 and 255, the higher the more discriminating\n",
    "    def pad_to_size(tile, target_size):\n",
    "        # Calcule la quantité de padding nécessaire\n",
    "        pad_height = max(0, target_size[0] - tile.shape[0])\n",
    "        pad_width = max(0, target_size[1] - tile.shape[1])\n",
    "\n",
    "        # Ajoute des colonnes de zéros à gauche et à droite\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "\n",
    "        # Ajoute des lignes de zéros en haut et en bas\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "\n",
    "        # Applique le padding\n",
    "        padded_tile = np.pad(tile, ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)), mode='constant', constant_values=0)\n",
    "\n",
    "        return padded_tile\n",
    "    tiles = [pad_to_size(image_array[i:i+tile_size, j:j+tile_size], (tile_size, tile_size, 3)) for i in range(0, image_array.shape[0], tile_size) for j in range(0, image_array.shape[1], tile_size)]\n",
    "    #print(tiles)\n",
    "    # 4. Élimination des carreaux de taille inférieure à un certain threshold\n",
    "    threshold = pix_threshold * tile_size**2 * 3 # Vous pouvez ajuster ce seuil en fonction de vos besoins\n",
    "    filtered_tiles = [tile for tile in tiles if np.sum(tile) > threshold]\n",
    "\n",
    "    # 5. Reconstruction d'un numpy array carré avec les tiles restant\n",
    "    num_tiles_side = int(np.sqrt(len(filtered_tiles)))\n",
    "\n",
    "    if (len(filtered_tiles) - num_tiles_side**2) != 0:\n",
    "        num_blank_tiles = (num_tiles_side+1)**2 - num_tiles_side**2\n",
    "        num_tiles_side = num_tiles_side + 1\n",
    "    else:\n",
    "        num_blank_tiles = 0\n",
    "\n",
    "    # Création de tiles blancs\n",
    "    blank_tile = np.zeros((tile_size, tile_size, 3), dtype=np.uint8)\n",
    "\n",
    "    # Remplissage des tiles manquants avec des tiles blanches\n",
    "    filled_tiles = filtered_tiles + [blank_tile] * num_blank_tiles\n",
    "\n",
    "    # Reconstruction du numpy array carré\n",
    "    reconstructed_array = np.vstack([np.hstack(filled_tiles[i*num_tiles_side:(i+1)*num_tiles_side]) for i in range(num_tiles_side)])\n",
    "\n",
    "    # 6. Enregistrement au format png\n",
    "    #reconstructed_image = Image.fromarray(reconstructed_array)\n",
    "    reconstructed_image = cv2.convertScaleAbs(reconstructed_array, cv2.COLOR_LAB2BGR)\n",
    "    reconstructed_image = cv2.resize(reconstructed_image, (2000, 2000), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    #base_name = os.path.basename(image_path)\n",
    "    # Create the folder if it doesn't exist\n",
    "    #os.makedirs(r\"reconstructed/\", exist_ok=True)\n",
    "    #folder = r\"reconstructed/\"\n",
    "    #full_name = ''.join([folder, base_name])\n",
    "    #reconstructed_image.save(full_name)\n",
    "    return reconstructed_image\n",
    "    #return reconstructed_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:12.537479Z",
     "iopub.status.busy": "2024-01-03T17:42:12.537034Z",
     "iopub.status.idle": "2024-01-03T17:42:13.900704Z",
     "shell.execute_reply": "2024-01-03T17:42:13.899650Z",
     "shell.execute_reply.started": "2024-01-03T17:42:12.537437Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example of an image Before and After normalization\n",
    "image_path = '/kaggle/input/UBC-OCEAN/train_thumbnails/5251_thumbnail.png'\n",
    "image_array = cv2.imread(image_path)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax[0].imshow(cv2.imread(image_path))\n",
    "\n",
    "ax[1].imshow(tiling_np_np(image_array))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:13.903090Z",
     "iopub.status.busy": "2024-01-03T17:42:13.902437Z",
     "iopub.status.idle": "2024-01-03T17:42:13.909325Z",
     "shell.execute_reply": "2024-01-03T17:42:13.908005Z",
     "shell.execute_reply.started": "2024-01-03T17:42:13.903049Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data augmentation method\n",
    "datagen_train = ImageDataGenerator(\n",
    "#    featurewise_center=True,\n",
    "#    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.25,# détermine le ratio training/validation\n",
    "    preprocessing_function=tiling_np_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:13.912353Z",
     "iopub.status.busy": "2024-01-03T17:42:13.911185Z",
     "iopub.status.idle": "2024-01-03T17:42:17.091475Z",
     "shell.execute_reply": "2024-01-03T17:42:17.090455Z",
     "shell.execute_reply.started": "2024-01-03T17:42:13.912308Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example of data augmentation + tiling\n",
    "image_path = '/kaggle/input/UBC-OCEAN/train_thumbnails/10143_thumbnail.png'\n",
    "img = cv2.imread(image_path) #/ 255.0  # Normalisez les valeurs de pixel à l'intervalle [0, 1]\n",
    "img = cv2.resize(img, (2000, 2000), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Ajouter une dimension pour obtenir une forme (1, height, width, channels)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Appliquer le prétraitement à l'image\n",
    "for img_batch in datagen_train.flow(img, batch_size=1):\n",
    "    img_augmented = img_batch[0]/255\n",
    "    break  # Break après le premier lot, car nous n'en avons qu'un\n",
    "\n",
    "# Assurez-vous que l'image est dans le format (height, width, channels)\n",
    "#img_augmented = img_augmented.squeeze()\n",
    "\n",
    "# Afficher l'image originale et l'image augmentée\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img.squeeze())\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_augmented)\n",
    "plt.title('Augmented Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:17.093408Z",
     "iopub.status.busy": "2024-01-03T17:42:17.092862Z",
     "iopub.status.idle": "2024-01-03T17:42:41.789375Z",
     "shell.execute_reply": "2024-01-03T17:42:41.788156Z",
     "shell.execute_reply.started": "2024-01-03T17:42:17.093375Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 4min35 for epochs = 1 and batch_size = 32\n",
    "# Model training\n",
    "with tf.device('/gpu:1'):\n",
    "    \n",
    "    # Call back creation\n",
    "    model_save_path = \"model_best_weights_3.h5\"\n",
    "    checkpoint = ModelCheckpoint(model_save_path, monitor='val_accuracy', verbose=1, mode='max', save_best_only=True)\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "    \n",
    "    # Training\n",
    "    history = model.fit(train_flow, epochs=epochs, \n",
    "                        steps_per_epoch=len(train_flow),\n",
    "                        callbacks=callbacks_list, \n",
    "                        validation_data=val_flow,\n",
    "                        validation_steps=len(val_flow),\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:41.791969Z",
     "iopub.status.busy": "2024-01-03T17:42:41.791241Z",
     "iopub.status.idle": "2024-01-03T17:42:52.269294Z",
     "shell.execute_reply": "2024-01-03T17:42:52.268105Z",
     "shell.execute_reply.started": "2024-01-03T17:42:41.791924Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Performances\n",
    "print('1/6-val accuracy/epochs')\n",
    "show_history(history)\n",
    "plot_history(history, path=\"history.png\")\n",
    "plt.close()\n",
    "\n",
    "print('2/6-predicting y_pred')\n",
    "#1min 28 for batch_size = 32\n",
    "y_pred = model.predict(val_flow, steps=len(val_flow), batch_size=batch_size)\n",
    "\n",
    "print('3/6-getting y_val')\n",
    "nombre_total_val = len(val_flow) * batch_size\n",
    "\n",
    "# Initialisation d'un tableau pour stocker les étiquettes réelles\n",
    "y_val = np.zeros((nombre_total_val, nb_lab))  \n",
    "\n",
    "# Itérer sur le générateur pour extraire les étiquettes réelles\n",
    "for i in range(len(val_flow)):\n",
    "    _, batch_y_val = val_flow[i]  # Supposons que le générateur génère des paires (X_val, y_val)\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + len(batch_y_val)\n",
    "    y_val[start_index:end_index] = batch_y_val\n",
    "\n",
    "print('4/6-building the basic confusion matrix')\n",
    "# Obtenez les indices des classes prédites et réelles pour les échantillons disponibles\n",
    "y_val_indices = y_val.argmax(axis=1)[0:len(y_pred)]\n",
    "y_pred_indices = y_pred.argmax(axis=1)\n",
    "\n",
    "# Générer la matrice de confusion\n",
    "cm = confusion_matrix(y_val_indices, y_pred_indices)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "print(cm)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(\"\\n5/6-building the classification report\")\n",
    "print(classification_report(y_val.argmax(axis=1)[0:len(y_pred)], y_pred.argmax(axis=1)))\n",
    "\n",
    "print('6/6-building the sns confusion matrix')\n",
    "# Finding the matching categorical labels for the numerical labels\n",
    "list_num_labels = sorted([x for x in set(y_val_indices)|set(y_pred_indices)])\n",
    "list_cat_labels = le.inverse_transform(list_num_labels)\n",
    "\n",
    "# Proceding with sns\n",
    "df_cm = pd.DataFrame(cm, index=list_cat_labels, columns=list_cat_labels)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "\n",
    "# Ajouter des étiquettes aux axes\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:52.270892Z",
     "iopub.status.busy": "2024-01-03T17:42:52.270533Z",
     "iopub.status.idle": "2024-01-03T17:42:52.279004Z",
     "shell.execute_reply": "2024-01-03T17:42:52.277584Z",
     "shell.execute_reply.started": "2024-01-03T17:42:52.270860Z"
    }
   },
   "outputs": [],
   "source": [
    "# recording method,val_accuracy, processing_time\n",
    "chrono = time() - chrono\n",
    "results.loc[len(results)] = ['Model3 : Data augmentation + Tiling',history.history['val_accuracy'][-1],chrono]\n",
    "chrono = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Model4-5-6 : Data augmentation + Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:52.280739Z",
     "iopub.status.busy": "2024-01-03T17:42:52.280403Z",
     "iopub.status.idle": "2024-01-03T17:42:52.443889Z",
     "shell.execute_reply": "2024-01-03T17:42:52.442164Z",
     "shell.execute_reply.started": "2024-01-03T17:42:52.280709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Comptez combien de fois chaque catégorie apparaît dans la colonne 'label'\n",
    "label_counts = data['label'].value_counts()\n",
    "\n",
    "# Créez un pie chart en utilisant les données de 'label_counts'\n",
    "plt.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-1 Balancing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:52.447329Z",
     "iopub.status.busy": "2024-01-03T17:42:52.446302Z",
     "iopub.status.idle": "2024-01-03T17:42:52.456106Z",
     "shell.execute_reply": "2024-01-03T17:42:52.454324Z",
     "shell.execute_reply.started": "2024-01-03T17:42:52.447259Z"
    }
   },
   "outputs": [],
   "source": [
    "data_0 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:52.459672Z",
     "iopub.status.busy": "2024-01-03T17:42:52.458045Z",
     "iopub.status.idle": "2024-01-03T17:42:52.467577Z",
     "shell.execute_reply": "2024-01-03T17:42:52.466288Z",
     "shell.execute_reply.started": "2024-01-03T17:42:52.459620Z"
    }
   },
   "outputs": [],
   "source": [
    "data_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:52.470650Z",
     "iopub.status.busy": "2024-01-03T17:42:52.469379Z",
     "iopub.status.idle": "2024-01-03T17:42:52.485282Z",
     "shell.execute_reply": "2024-01-03T17:42:52.484090Z",
     "shell.execute_reply.started": "2024-01-03T17:42:52.470598Z"
    }
   },
   "outputs": [],
   "source": [
    "# For stage 1\n",
    "# in original dataset we have 41.3% HGSC - 23% EC - 18.4% CC - 8.7% LGSC - 8.6% MC\n",
    "# we'll change these proportion to X EC - X CC - 8.7 LGSC - 8.6 MC = 41.3 HGSC\n",
    "# [41.3 - (8.7 + 8.6)] / 2 = 12\n",
    "# Passing EC size from 23 to 12 :\n",
    "data_EC = data.loc[data['label']== 'EC',:]\n",
    "data_EC_reduced = data_EC.iloc[0:int(len(data_EC)*12/23)]\n",
    "data_EC_reduced['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:52.488091Z",
     "iopub.status.busy": "2024-01-03T17:42:52.487208Z",
     "iopub.status.idle": "2024-01-03T17:42:52.505060Z",
     "shell.execute_reply": "2024-01-03T17:42:52.503808Z",
     "shell.execute_reply.started": "2024-01-03T17:42:52.488045Z"
    }
   },
   "outputs": [],
   "source": [
    "# Passing CC size from 18.4 to 12\n",
    "data_CC = data.loc[data['label']== 'CC',:]\n",
    "data_CC_reduced = data_CC.iloc[0:int(len(data_CC)*12/18.4)]\n",
    "data_CC_reduced['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:52.507664Z",
     "iopub.status.busy": "2024-01-03T17:42:52.507177Z",
     "iopub.status.idle": "2024-01-03T17:42:52.523584Z",
     "shell.execute_reply": "2024-01-03T17:42:52.522165Z",
     "shell.execute_reply.started": "2024-01-03T17:42:52.507620Z"
    }
   },
   "outputs": [],
   "source": [
    "# New data concatenate data_HGSC, data_EC_reduced, data_CC_reduced, data_LGSC and data_MC\n",
    "data_HGSC_LGSC_MC = data.loc[data['label'].isin(['HGSC','LGSC','MC']),:]\n",
    "new_data_1 = pd.concat([data_HGSC_LGSC_MC, data_EC_reduced])\n",
    "new_data_1 = pd.concat([new_data_1, data_CC_reduced])\n",
    "new_data_1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:52.525700Z",
     "iopub.status.busy": "2024-01-03T17:42:52.525341Z",
     "iopub.status.idle": "2024-01-03T17:42:52.539295Z",
     "shell.execute_reply": "2024-01-03T17:42:52.537907Z",
     "shell.execute_reply.started": "2024-01-03T17:42:52.525669Z"
    }
   },
   "outputs": [],
   "source": [
    "new_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:52.541525Z",
     "iopub.status.busy": "2024-01-03T17:42:52.540971Z",
     "iopub.status.idle": "2024-01-03T17:42:52.552760Z",
     "shell.execute_reply": "2024-01-03T17:42:52.551789Z",
     "shell.execute_reply.started": "2024-01-03T17:42:52.541487Z"
    }
   },
   "outputs": [],
   "source": [
    "# Renaming classes EC, CC, LGSC and MC as Other\n",
    "new_data_1['label'] = new_data_1['label'].apply(lambda x: 'Other' if x in ['EC', 'CC', 'LGSC', 'MC'] else x)\n",
    "# Check \n",
    "new_data_1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:52.555078Z",
     "iopub.status.busy": "2024-01-03T17:42:52.554142Z",
     "iopub.status.idle": "2024-01-03T17:42:52.569860Z",
     "shell.execute_reply": "2024-01-03T17:42:52.568558Z",
     "shell.execute_reply.started": "2024-01-03T17:42:52.555044Z"
    }
   },
   "outputs": [],
   "source": [
    "# For stage 2\n",
    "# We reduce data to labels EC - CC - LGSC - MC\n",
    "# We divide EC - CC - LGSC - MC into EC - CC and Other\n",
    "new_data_2 = data.loc[data['label'].isin(['EC','CC','LGSC','MC']),:]\n",
    "new_data_2['label'] = new_data_2['label'].apply(lambda x : 'Other' if x in ['LGSC','MC'] else x)\n",
    "# Check\n",
    "new_data_2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:52.572563Z",
     "iopub.status.busy": "2024-01-03T17:42:52.572074Z",
     "iopub.status.idle": "2024-01-03T17:42:52.586058Z",
     "shell.execute_reply": "2024-01-03T17:42:52.585025Z",
     "shell.execute_reply.started": "2024-01-03T17:42:52.572518Z"
    }
   },
   "outputs": [],
   "source": [
    "# For stage 3\n",
    "# We keep only LGSC and MC\n",
    "new_data_3 = data.loc[data['label'].isin(['LGSC','MC']),:]\n",
    "# Check\n",
    "new_data_3['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-2 Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:52.587883Z",
     "iopub.status.busy": "2024-01-03T17:42:52.587453Z",
     "iopub.status.idle": "2024-01-03T17:42:52.597464Z",
     "shell.execute_reply": "2024-01-03T17:42:52.596506Z",
     "shell.execute_reply.started": "2024-01-03T17:42:52.587766Z"
    }
   },
   "outputs": [],
   "source": [
    "# Méthode d'augmentation des données\n",
    "datagen_train = ImageDataGenerator(\n",
    "#    featurewise_center=True,\n",
    "#    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.25,# détermine le ration training/validation\n",
    "    preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-3 Stage 1 : HGSC vs Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3-1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:42:52.599119Z",
     "iopub.status.busy": "2024-01-03T17:42:52.598809Z",
     "iopub.status.idle": "2024-01-03T17:43:15.677255Z",
     "shell.execute_reply": "2024-01-03T17:43:15.675843Z",
     "shell.execute_reply.started": "2024-01-03T17:42:52.599092Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Model training on HGSC - other data')\n",
    "data = new_data_1\n",
    "\n",
    "# Number of classes\n",
    "nb_lab_1 = len(data['label'].unique())\n",
    "\n",
    "# Class list\n",
    "le1 = LabelEncoder()\n",
    "le1.fit_transform(data['label'])\n",
    "list_lab_1 = le1.classes_\n",
    "#['HGSC', 'Other']\n",
    "\n",
    "print('1-Model creation (!new nb_lab!)')\n",
    "# Model creation\n",
    "# 408ms\n",
    "\n",
    "with tf.device('/gpu:1'): \n",
    "    model = create_model_fct(nb_lab_1)\n",
    "    # Call back creation\n",
    "    model_save_path = \"model_best_weights_4.h5\"\n",
    "    checkpoint = ModelCheckpoint(model_save_path, monitor='val_accuracy', verbose=1, mode='max', save_best_only=True)\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "\n",
    "print('2-Data augmentation - train-val split')\n",
    "# Augmentation des données et split en train et val\n",
    "train_flow = data_flow_fct(data, datagen_train, data_type='training',batch_size=batch_size)#divisor_train)\n",
    "val_flow = data_flow_fct(data, datagen_train, data_type='validation',batch_size=batch_size)#divisor_val)\n",
    "\n",
    "print('3-Model training')\n",
    "# Training\n",
    "history = model.fit(train_flow, epochs=epochs, \n",
    "                    steps_per_epoch=len(train_flow),\n",
    "                    callbacks=callbacks_list, \n",
    "                    validation_data=val_flow,\n",
    "                    validation_steps=len(val_flow),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3-2 Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:43:15.680376Z",
     "iopub.status.busy": "2024-01-03T17:43:15.679431Z",
     "iopub.status.idle": "2024-01-03T17:43:25.233076Z",
     "shell.execute_reply": "2024-01-03T17:43:25.231806Z",
     "shell.execute_reply.started": "2024-01-03T17:43:15.680315Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Performances\n",
    "print('1/6-val accuracy/epochs')\n",
    "show_history(history)\n",
    "plot_history(history, path=\"history.png\")\n",
    "plt.close()\n",
    "\n",
    "print('2/6-predicting y_pred')\n",
    "#1min 28 for batch_size = 32\n",
    "y_pred = model.predict(val_flow, steps=len(val_flow), batch_size=batch_size)\n",
    "\n",
    "print('3/6-getting y_val')\n",
    "nombre_total_val = len(val_flow) * batch_size\n",
    "\n",
    "# Initialisation d'un tableau pour stocker les étiquettes réelles\n",
    "y_val = np.zeros((nombre_total_val, nb_lab_1))  \n",
    "\n",
    "# Itérer sur le générateur pour extraire les étiquettes réelles\n",
    "for i in range(len(val_flow)):\n",
    "    _, batch_y_val = val_flow[i]  # Supposons que le générateur génère des paires (X_val, y_val)\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + len(batch_y_val)\n",
    "    y_val[start_index:end_index] = batch_y_val\n",
    "\n",
    "print('4/6-building the basic confusion matrix')\n",
    "# Obtenez les indices des classes prédites et réelles pour les échantillons disponibles\n",
    "y_val_indices = y_val.argmax(axis=1)[0:len(y_pred)]\n",
    "y_pred_indices = y_pred.argmax(axis=1)\n",
    "\n",
    "# Générer la matrice de confusion\n",
    "cm = confusion_matrix(y_val_indices, y_pred_indices)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "print(cm)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(\"\\n5/6-building the classification report\")\n",
    "print(classification_report(y_val.argmax(axis=1)[0:len(y_pred)], y_pred.argmax(axis=1)))\n",
    "\n",
    "print('6/6-building the sns confusion matrix')\n",
    "# Finding the matching categorical labels for the numerical labels\n",
    "list_num_labels = sorted([x for x in set(y_val_indices)|set(y_pred_indices)])\n",
    "list_cat_labels = le1.inverse_transform(list_num_labels)\n",
    "\n",
    "# Proceding with sns\n",
    "df_cm = pd.DataFrame(cm, index=list_cat_labels, columns=list_cat_labels)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "\n",
    "# Ajouter des étiquettes aux axes\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3-3 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:43:25.234789Z",
     "iopub.status.busy": "2024-01-03T17:43:25.234450Z",
     "iopub.status.idle": "2024-01-03T17:43:37.744750Z",
     "shell.execute_reply": "2024-01-03T17:43:37.743301Z",
     "shell.execute_reply.started": "2024-01-03T17:43:25.234759Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "# Méthode d'augmentation des données\n",
    "datagen_test = ImageDataGenerator(\n",
    "    #no transformation necessary for prediction\n",
    "    validation_split=None,# no test/train split for prediction\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "# Fonction d'augmentation des données\n",
    "def data_flow_fct(data, datagen, data_type=None, batch_size=None):\n",
    "    data_flow = datagen.flow_from_dataframe(data,\n",
    "                                            x_col='image_path',\n",
    "                                            y_col='label',\n",
    "                                            weight_col=None,\n",
    "                                            target_size=(256, 256),\n",
    "                                            classes=None,\n",
    "                                            class_mode='categorical',\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,  # Ne pas mélanger les données pour garantir l'ordre correct des prédictions\n",
    "                                            seed=42,\n",
    "                                            subset=data_type)\n",
    "    return data_flow\n",
    "\n",
    "# Création du générateur de flux de test\n",
    "test_flow = data_flow_fct(data, datagen_test, data_type=None, batch_size=1)\n",
    "\n",
    "# Prédiction des étiquettes\n",
    "y_pred = model.predict(test_flow)\n",
    "\n",
    "# Ajout des prédictions au DataFrame\n",
    "data['prediction'] = list(map(lambda x: le1.inverse_transform(np.array([np.argmax(x)]))[0], y_pred))\n",
    "data_1 = data.copy()\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:43:37.747034Z",
     "iopub.status.busy": "2024-01-03T17:43:37.746582Z",
     "iopub.status.idle": "2024-01-03T17:43:38.046091Z",
     "shell.execute_reply": "2024-01-03T17:43:38.044966Z",
     "shell.execute_reply.started": "2024-01-03T17:43:37.746989Z"
    }
   },
   "outputs": [],
   "source": [
    "print('4/6-building the basic confusion matrix')\n",
    "# Obtenez les indices des classes prédites et réelles pour les échantillons disponibles\n",
    "y_val_indices = data_1['label']\n",
    "y_pred_indices = data_1['prediction']\n",
    "\n",
    "# Générer la matrice de confusion\n",
    "cm = confusion_matrix(y_val_indices, y_pred_indices)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "print(cm)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(\"\\n5/6-building the classification report\")\n",
    "print(classification_report(y_val_indices, y_pred_indices))\n",
    "\n",
    "print('6/6-building the sns confusion matrix')\n",
    "# Finding the matching categorical labels for the numerical labels\n",
    "list_cat_labels = sorted([x for x in set(y_val_indices)|set(y_pred_indices)])\n",
    "\n",
    "# Proceding with sns\n",
    "df_cm = pd.DataFrame(cm, index=list_cat_labels, columns=list_cat_labels)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.heatmap(df_cm, annot=True, cmap=\"Reds\")\n",
    "\n",
    "# Ajouter des étiquettes aux axes\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-4 Stage 2 : EC vs CC vs Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-4-1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:43:38.048726Z",
     "iopub.status.busy": "2024-01-03T17:43:38.048394Z",
     "iopub.status.idle": "2024-01-03T17:43:51.064576Z",
     "shell.execute_reply": "2024-01-03T17:43:51.063734Z",
     "shell.execute_reply.started": "2024-01-03T17:43:38.048697Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Model training on EC vs CC vs Others')\n",
    "data = new_data_2\n",
    "\n",
    "# Number of classes\n",
    "nb_lab_2 = len(data['label'].unique())\n",
    "\n",
    "# Class list\n",
    "le2 = LabelEncoder()\n",
    "le2.fit_transform(data['label'])\n",
    "list_lab_2 = le2.classes_\n",
    "#['HGSC', 'Other']\n",
    "\n",
    "print('1-Model creation (!new nb_lab!)')\n",
    "# Model creation\n",
    "# 408ms\n",
    "\n",
    "with tf.device('/gpu:1'): \n",
    "    model = create_model_fct(nb_lab_2)\n",
    "    # Call back creation\n",
    "    model_save_path = \"model_best_weights_5.h5\"\n",
    "    checkpoint = ModelCheckpoint(model_save_path, monitor='val_accuracy', verbose=1, mode='max', save_best_only=True)\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "\n",
    "print('2-Data augmentation - train-val split')\n",
    "# Augmentation des données et split en train et val\n",
    "train_flow = data_flow_fct(data, datagen_train, data_type='training',batch_size=batch_size)#divisor_train)\n",
    "val_flow = data_flow_fct(data, datagen_train, data_type='validation',batch_size=batch_size)#divisor_val)\n",
    "\n",
    "print('3-Model training')\n",
    "# Training\n",
    "history = model.fit(train_flow, epochs=epochs, \n",
    "                    steps_per_epoch=len(train_flow),\n",
    "                    callbacks=callbacks_list, \n",
    "                    validation_data=val_flow,\n",
    "                    validation_steps=len(val_flow),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-4-2 Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:43:51.066301Z",
     "iopub.status.busy": "2024-01-03T17:43:51.065915Z",
     "iopub.status.idle": "2024-01-03T17:43:56.191469Z",
     "shell.execute_reply": "2024-01-03T17:43:56.190321Z",
     "shell.execute_reply.started": "2024-01-03T17:43:51.066253Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Performances\n",
    "print('1/6-val accuracy/epochs')\n",
    "show_history(history)\n",
    "plot_history(history, path=\"history.png\")\n",
    "plt.close()\n",
    "\n",
    "print('2/6-predicting y_pred')\n",
    "#1min 28 for batch_size = 32\n",
    "y_pred = model.predict(val_flow, steps=len(val_flow), batch_size=batch_size)\n",
    "\n",
    "print('3/6-getting y_val')\n",
    "nombre_total_val = len(val_flow) * batch_size\n",
    "\n",
    "# Initialisation d'un tableau pour stocker les étiquettes réelles\n",
    "y_val = np.zeros((nombre_total_val, nb_lab_2))  \n",
    "\n",
    "# Itérer sur le générateur pour extraire les étiquettes réelles\n",
    "for i in range(len(val_flow)):\n",
    "    _, batch_y_val = val_flow[i]  # Supposons que le générateur génère des paires (X_val, y_val)\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + len(batch_y_val)\n",
    "    y_val[start_index:end_index] = batch_y_val\n",
    "\n",
    "print('4/6-building the basic confusion matrix')\n",
    "# Obtenez les indices des classes prédites et réelles pour les échantillons disponibles\n",
    "y_val_indices = y_val.argmax(axis=1)[0:len(y_pred)]\n",
    "y_pred_indices = y_pred.argmax(axis=1)\n",
    "\n",
    "# Générer la matrice de confusion\n",
    "cm = confusion_matrix(y_val_indices, y_pred_indices)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "print(cm)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(\"\\n5/6-building the classification report\")\n",
    "print(classification_report(y_val.argmax(axis=1)[0:len(y_pred)], y_pred.argmax(axis=1)))\n",
    "\n",
    "print('6/6-building the sns confusion matrix')\n",
    "# Finding the matching categorical labels for the numerical labels\n",
    "list_num_labels = sorted([x for x in set(y_val_indices)|set(y_pred_indices)])\n",
    "list_cat_labels = le2.inverse_transform(list_num_labels)\n",
    "\n",
    "# Proceding with sns\n",
    "df_cm = pd.DataFrame(cm, index=list_cat_labels, columns=list_cat_labels)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "\n",
    "# Ajouter des étiquettes aux axes\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-4-3 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:43:56.193513Z",
     "iopub.status.busy": "2024-01-03T17:43:56.193054Z",
     "iopub.status.idle": "2024-01-03T17:44:02.645890Z",
     "shell.execute_reply": "2024-01-03T17:44:02.644780Z",
     "shell.execute_reply.started": "2024-01-03T17:43:56.193470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "# Méthode d'augmentation des données\n",
    "datagen_test = ImageDataGenerator(\n",
    "    #no transformation necessary for prediction\n",
    "    validation_split=None,# no test/train split for prediction\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "# Fonction d'augmentation des données\n",
    "def data_flow_fct(data, datagen, data_type=None, batch_size=None):\n",
    "    data_flow = datagen.flow_from_dataframe(data,\n",
    "                                            x_col='image_path',\n",
    "                                            y_col='label',\n",
    "                                            weight_col=None,\n",
    "                                            target_size=(256, 256),\n",
    "                                            classes=None,\n",
    "                                            class_mode='categorical',\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,  # Ne pas mélanger les données pour garantir l'ordre correct des prédictions\n",
    "                                            seed=42,\n",
    "                                            subset=data_type)\n",
    "    return data_flow\n",
    "\n",
    "# Création du générateur de flux de test\n",
    "test_flow = data_flow_fct(data, datagen_test, data_type=None, batch_size=1)\n",
    "\n",
    "# Prédiction des étiquettes\n",
    "y_pred = model.predict(test_flow)\n",
    "\n",
    "# Ajout des prédictions au DataFrame\n",
    "data['prediction'] = list(map(lambda x: le2.inverse_transform(np.array([np.argmax(x)]))[0], y_pred))\n",
    "data_2 = data.copy()\n",
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:44:02.649320Z",
     "iopub.status.busy": "2024-01-03T17:44:02.648270Z",
     "iopub.status.idle": "2024-01-03T17:44:02.967246Z",
     "shell.execute_reply": "2024-01-03T17:44:02.966041Z",
     "shell.execute_reply.started": "2024-01-03T17:44:02.649279Z"
    }
   },
   "outputs": [],
   "source": [
    "print('4/6-building the basic confusion matrix')\n",
    "# Obtenez les indices des classes prédites et réelles pour les échantillons disponibles\n",
    "y_val_indices = data_2['label']\n",
    "y_pred_indices = data_2['prediction']\n",
    "\n",
    "# Générer la matrice de confusion\n",
    "cm = confusion_matrix(y_val_indices, y_pred_indices)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "print(cm)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(\"\\n5/6-building the classification report\")\n",
    "print(classification_report(y_val_indices, y_pred_indices))\n",
    "\n",
    "print('6/6-building the sns confusion matrix')\n",
    "# Finding the matching categorical labels for the numerical labels\n",
    "list_cat_labels = sorted([x for x in set(y_val_indices)|set(y_pred_indices)])\n",
    "\n",
    "# Proceeding with sns\n",
    "df_cm = pd.DataFrame(cm, index=list_cat_labels, columns=list_cat_labels)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.heatmap(df_cm, annot=True, cmap=\"Reds\")\n",
    "\n",
    "# Ajouter des étiquettes aux axes\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-5 Stage 3 : LGSC and MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-5-1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:44:02.968654Z",
     "iopub.status.busy": "2024-01-03T17:44:02.968337Z",
     "iopub.status.idle": "2024-01-03T17:44:09.467867Z",
     "shell.execute_reply": "2024-01-03T17:44:09.466726Z",
     "shell.execute_reply.started": "2024-01-03T17:44:02.968626Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Model training on LGSC and MC data')\n",
    "data = new_data_3\n",
    "\n",
    "# Number of classes\n",
    "nb_lab_3 = len(data['label'].unique())\n",
    "\n",
    "# Class list\n",
    "le3 = LabelEncoder()\n",
    "le3.fit_transform(data['label'])\n",
    "list_lab_3 = le3.classes_\n",
    "#['HGSC', 'Other']\n",
    "\n",
    "print('1-Model creation (!new nb_lab!)')\n",
    "# Model creation\n",
    "# 408ms\n",
    "\n",
    "with tf.device('/gpu:1'): \n",
    "    model = create_model_fct(nb_lab_3)\n",
    "    # Call back creation\n",
    "    model_save_path = \"model_best_weights_6.h5\"\n",
    "    checkpoint = ModelCheckpoint(model_save_path, monitor='val_accuracy', verbose=1, mode='max', save_best_only=True)\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "\n",
    "print('2-Data augmentation - train-val split')\n",
    "# Augmentation des données et split en train et val\n",
    "train_flow = data_flow_fct(data, datagen_train, data_type='training',batch_size=batch_size)#divisor_train)\n",
    "val_flow = data_flow_fct(data, datagen_train, data_type='validation',batch_size=batch_size)#divisor_val)\n",
    "\n",
    "print('3-Model training')\n",
    "# Training\n",
    "history = model.fit(train_flow, epochs=epochs, \n",
    "                    steps_per_epoch=len(train_flow),\n",
    "                    callbacks=callbacks_list, \n",
    "                    validation_data=val_flow,\n",
    "                    validation_steps=len(val_flow),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-5-2 Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:44:09.472644Z",
     "iopub.status.busy": "2024-01-03T17:44:09.471539Z",
     "iopub.status.idle": "2024-01-03T17:44:12.493007Z",
     "shell.execute_reply": "2024-01-03T17:44:12.491923Z",
     "shell.execute_reply.started": "2024-01-03T17:44:09.472599Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Performances\n",
    "print('1/6-val accuracy/epochs')\n",
    "show_history(history)\n",
    "plot_history(history, path=\"history.png\")\n",
    "plt.close()\n",
    "\n",
    "print('2/6-predicting y_pred')\n",
    "#1min 28 for batch_size = 32\n",
    "y_pred = model.predict(val_flow, steps=len(val_flow), batch_size=batch_size)\n",
    "\n",
    "print('3/6-getting y_val')\n",
    "nombre_total_val = len(val_flow) * batch_size\n",
    "\n",
    "# Initialisation d'un tableau pour stocker les étiquettes réelles\n",
    "y_val = np.zeros((nombre_total_val, nb_lab_3))  \n",
    "\n",
    "# Itérer sur le générateur pour extraire les étiquettes réelles\n",
    "for i in range(len(val_flow)):\n",
    "    _, batch_y_val = val_flow[i]  # Supposons que le générateur génère des paires (X_val, y_val)\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + len(batch_y_val)\n",
    "    y_val[start_index:end_index] = batch_y_val\n",
    "\n",
    "print('4/6-building the basic confusion matrix')\n",
    "# Obtenez les indices des classes prédites et réelles pour les échantillons disponibles\n",
    "y_val_indices = y_val.argmax(axis=1)[0:len(y_pred)]\n",
    "y_pred_indices = y_pred.argmax(axis=1)\n",
    "\n",
    "# Générer la matrice de confusion\n",
    "cm = confusion_matrix(y_val_indices, y_pred_indices)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "print(cm)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(\"\\n5/6-building the classification report\")\n",
    "print(classification_report(y_val.argmax(axis=1)[0:len(y_pred)], y_pred.argmax(axis=1)))\n",
    "\n",
    "print('6/6-building the sns confusion matrix')\n",
    "# Finding the matching categorical labels for the numerical labels\n",
    "list_num_labels = sorted([x for x in set(y_val_indices)|set(y_pred_indices)])\n",
    "list_cat_labels = le3.inverse_transform(list_num_labels)\n",
    "\n",
    "# Proceding with sns\n",
    "df_cm = pd.DataFrame(cm, index=list_cat_labels, columns=list_cat_labels)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "\n",
    "# Ajouter des étiquettes aux axes\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-5-3 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:44:12.494992Z",
     "iopub.status.busy": "2024-01-03T17:44:12.494622Z",
     "iopub.status.idle": "2024-01-03T17:44:15.570532Z",
     "shell.execute_reply": "2024-01-03T17:44:15.569381Z",
     "shell.execute_reply.started": "2024-01-03T17:44:12.494959Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "# Méthode d'augmentation des données\n",
    "datagen_test = ImageDataGenerator(\n",
    "    #no transformation necessary for prediction\n",
    "    validation_split=None,# no test/train split for prediction\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "# Fonction d'augmentation des données\n",
    "def data_flow_fct(data, datagen, data_type=None, batch_size=None):\n",
    "    data_flow = datagen.flow_from_dataframe(data,\n",
    "                                            x_col='image_path',\n",
    "                                            y_col='label',\n",
    "                                            weight_col=None,\n",
    "                                            target_size=(256, 256),\n",
    "                                            classes=None,\n",
    "                                            class_mode='categorical',\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,  # Ne pas mélanger les données pour garantir l'ordre correct des prédictions\n",
    "                                            seed=42,\n",
    "                                            subset=data_type)\n",
    "    return data_flow\n",
    "\n",
    "# Création du générateur de flux de test\n",
    "test_flow = data_flow_fct(data, datagen_test, data_type=None, batch_size=1)\n",
    "\n",
    "# Prédiction des étiquettes\n",
    "y_pred = model.predict(test_flow)\n",
    "\n",
    "# Ajout des prédictions au DataFrame\n",
    "data['prediction'] = list(map(lambda x: le3.inverse_transform(np.array([np.argmax(x)]))[0], y_pred))\n",
    "data_3 = data.copy()\n",
    "data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:44:15.573033Z",
     "iopub.status.busy": "2024-01-03T17:44:15.572211Z",
     "iopub.status.idle": "2024-01-03T17:44:15.942916Z",
     "shell.execute_reply": "2024-01-03T17:44:15.941354Z",
     "shell.execute_reply.started": "2024-01-03T17:44:15.572986Z"
    }
   },
   "outputs": [],
   "source": [
    "print('4/6-building the basic confusion matrix')\n",
    "# Obtenez les indices des classes prédites et réelles pour les échantillons disponibles\n",
    "y_val_indices = data_3['label']\n",
    "y_pred_indices = data_3['prediction']\n",
    "\n",
    "# Générer la matrice de confusion\n",
    "cm = confusion_matrix(y_val_indices, y_pred_indices)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "print(cm)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(\"\\n5/6-building the classification report\")\n",
    "print(classification_report(y_val_indices, y_pred_indices))\n",
    "\n",
    "print('6/6-building the sns confusion matrix')\n",
    "# Finding the matching categorical labels for the numerical labels\n",
    "list_cat_labels = sorted([x for x in set(y_val_indices)|set(y_pred_indices)])\n",
    "\n",
    "# Proceding with sns\n",
    "df_cm = pd.DataFrame(cm, index=list_cat_labels, columns=list_cat_labels)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.heatmap(df_cm, annot=True, cmap=\"Reds\")\n",
    "\n",
    "# Ajouter des étiquettes aux axes\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:44:15.945689Z",
     "iopub.status.busy": "2024-01-03T17:44:15.944860Z",
     "iopub.status.idle": "2024-01-03T17:44:15.956780Z",
     "shell.execute_reply": "2024-01-03T17:44:15.955181Z",
     "shell.execute_reply.started": "2024-01-03T17:44:15.945640Z"
    }
   },
   "outputs": [],
   "source": [
    "y_val_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-6 Stacking predictions from model_1, model_2 and model_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-6-1 Data concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:44:15.958710Z",
     "iopub.status.busy": "2024-01-03T17:44:15.958298Z",
     "iopub.status.idle": "2024-01-03T17:44:15.970794Z",
     "shell.execute_reply": "2024-01-03T17:44:15.969745Z",
     "shell.execute_reply.started": "2024-01-03T17:44:15.958675Z"
    }
   },
   "outputs": [],
   "source": [
    "data_stack = pd.concat([data_1, data_2])\n",
    "data_stack = pd.concat([data_stack,data_3])\n",
    "print(data_stack.shape)\n",
    "data_stack = data_stack.loc[data_stack['label']!='Other',:]\n",
    "print(data_stack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:44:15.973176Z",
     "iopub.status.busy": "2024-01-03T17:44:15.972181Z",
     "iopub.status.idle": "2024-01-03T17:44:15.992633Z",
     "shell.execute_reply": "2024-01-03T17:44:15.991362Z",
     "shell.execute_reply.started": "2024-01-03T17:44:15.973130Z"
    }
   },
   "outputs": [],
   "source": [
    "data_stack.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-6-2 Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:44:15.994749Z",
     "iopub.status.busy": "2024-01-03T17:44:15.994350Z",
     "iopub.status.idle": "2024-01-03T17:44:16.002640Z",
     "shell.execute_reply": "2024-01-03T17:44:16.001407Z",
     "shell.execute_reply.started": "2024-01-03T17:44:15.994717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label processing\n",
    "data = data_stack\n",
    "\n",
    "# Number of classes\n",
    "nb_lab_4 = len(data['label'].unique())\n",
    "\n",
    "# Class list\n",
    "le4 = LabelEncoder()\n",
    "le4.fit_transform(data['label'])\n",
    "list_lab_4 = le4.classes_\n",
    "#['HGSC', 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:44:16.005625Z",
     "iopub.status.busy": "2024-01-03T17:44:16.004915Z",
     "iopub.status.idle": "2024-01-03T17:44:16.430640Z",
     "shell.execute_reply": "2024-01-03T17:44:16.429265Z",
     "shell.execute_reply.started": "2024-01-03T17:44:16.005578Z"
    }
   },
   "outputs": [],
   "source": [
    "print('4/6-building the basic confusion matrix')\n",
    "# Obtenez les indices des classes prédites et réelles pour les échantillons disponibles\n",
    "y_val_indices = data_stack['label']\n",
    "y_pred_indices = data_stack['prediction']\n",
    "\n",
    "# Générer la matrice de confusion\n",
    "cm = confusion_matrix(y_val_indices, y_pred_indices)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "print(cm)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(\"\\n5/6-building the classification report\")\n",
    "print(classification_report(y_val_indices, y_pred_indices))\n",
    "\n",
    "print('6/6-building the sns confusion matrix')\n",
    "# Finding the matching categorical labels for the numerical labels\n",
    "list_cat_labels = sorted([x for x in set(y_val_indices)|set(y_pred_indices)])\n",
    "\n",
    "# Proceding with sns\n",
    "df_cm = pd.DataFrame(cm, index=list_cat_labels, columns=list_cat_labels)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.heatmap(df_cm, annot=True, cmap=\"Reds\")\n",
    "\n",
    "# Ajouter des étiquettes aux axes\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T17:44:16.434368Z",
     "iopub.status.busy": "2024-01-03T17:44:16.433552Z",
     "iopub.status.idle": "2024-01-03T17:44:16.455550Z",
     "shell.execute_reply": "2024-01-03T17:44:16.454306Z",
     "shell.execute_reply.started": "2024-01-03T17:44:16.434319Z"
    }
   },
   "outputs": [],
   "source": [
    "chrono = time() - chrono\n",
    "# recording method,val_accuracy, processing_time\n",
    "results.loc[len(results)] = ['Model4-5-6 : Data augmentation + Balancing',accuracy_score(y_val_indices,y_pred_indices),chrono]\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6924515,
     "sourceId": 45867,
     "sourceType": "competition"
    },
    {
     "datasetId": 4254700,
     "sourceId": 7329788,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
